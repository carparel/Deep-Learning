{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import dlc_practical_prologue as prologue\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input size = torch.Size([1000, 2, 14, 14])\n",
      "train_target size = torch.Size([1000])\n",
      "train_classes size = torch.Size([1000, 2])\n",
      "test_input size = torch.Size([1000, 2, 14, 14])\n",
      "test_target size = torch.Size([1000])\n",
      "test_classes size = torch.Size([1000, 2])\n"
     ]
    }
   ],
   "source": [
    "nbr_pairs = 1000\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(nbr_pairs)\n",
    "\n",
    "print('train_input size =', train_input.size())\n",
    "print('train_target size =', train_target.size()) #The boolean telling if the two pairs are the same or not \n",
    "print('train_classes size =', train_classes.size())\n",
    "print('test_input size =', test_input.size())\n",
    "print('test_target size =', test_target.size())\n",
    "print('test_classes size =', test_classes.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_NOaux(model, train_input, train_target, nb_epochs, batch_size, criterion, eta): \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = eta)\n",
    "    for e in range(nb_epochs):\n",
    "        if (e % 10 == 0 and e > 0):\n",
    "            eta = eta/10\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr = eta)\n",
    "        for step_ in range(0,train_input.size(0),batch_size):                              \n",
    "            output = model(train_input[step_:step_+batch_size])\n",
    "            loss = criterion(output, train_target[step_:step_+batch_size])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def train_model_aux(model, train_input, train_target, nb_epochs, batch_size, criterion, eta, lambda_):   \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = eta)\n",
    "    for e in range(nb_epochs):\n",
    "        if (e % 10 == 0 and e > 0):\n",
    "            eta = eta/10\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr = eta)\n",
    "        for step_ in range(0,train_input.size(0),batch_size):                              \n",
    "            output_target, output_im1, output_im2 = model(train_input[step_:step_+batch_size])\n",
    "            loss_target = criterion(output_target, train_target[step_:step_+batch_size])\n",
    "            loss_im1 = criterion(output_im1, train_classes[step_:step_+batch_size,0])\n",
    "            loss_im2 = criterion(output_im2, train_classes[step_:step_+batch_size,1])\n",
    "            loss = loss_target + lambda_*(loss_im1 + loss_im2)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors_NOaux(model, data_input, data_target, mini_batch_size): \n",
    "    nb_errors = 0\n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\n",
    "        output = model(data_input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = output.data.max(1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if data_target[b + k] != predicted_classes[k]:\n",
    "                nb_errors = nb_errors + 1\n",
    "    return nb_errors\n",
    "\n",
    "def compute_nb_errors_aux(model, data_input, data_target, mini_batch_size): \n",
    "    nb_errors = 0\n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\n",
    "        output,_,_ = model(data_input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = output.data.max(1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if data_target[b + k] != predicted_classes[k]:\n",
    "                nb_errors = nb_errors + 1\n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shallow_NOsharing_NOaux(nn.Module):\n",
    "    def __init__(self, hidden, act_fun):\n",
    "        super(Shallow_NOsharing_NOaux, self).__init__()\n",
    "        self.act_fun = act_fun\n",
    "        self.fc1_1 = nn.Linear(196, hidden)\n",
    "        self.fc1_2 = nn.Linear(196, hidden)\n",
    "        # After concatenation of the features from image 1 and image 2\n",
    "        self.fc2 = nn.Linear(hidden*2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1 = self.act_fun(self.fc1_1(x[:,0,:,:].view(-1,196)))\n",
    "        x_2 = self.act_fun(self.fc1_2(x[:,1,:,:].view(-1,196)))\n",
    "        x = torch.cat([x_1, x_2],1)\n",
    "        x = self.fc2(x)       \n",
    "        return x\n",
    "    \n",
    "class Shallow_sharing_NOaux(nn.Module):\n",
    "    def __init__(self, hidden, act_fun):\n",
    "        super(Shallow_sharing_NOaux, self).__init__()\n",
    "        self.act_fun = act_fun\n",
    "        self.fc1 = nn.Linear(196, hidden)\n",
    "        # After concatenation of the features from image 1 and image 2\n",
    "        self.fc2 = nn.Linear(hidden*2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fc_image = []\n",
    "        for image in range(2):\n",
    "            x1 = self.act_fun(self.fc1(x[:,image,:,:].view(-1,196)))\n",
    "            fc_image.append(x1)\n",
    "        x = torch.cat([fc_image[0],fc_image[1]],1)\n",
    "        x = self.fc2(x)       \n",
    "        return x\n",
    "    \n",
    "class Shallow_NOsharing_aux(nn.Module):\n",
    "    def __init__(self, hidden, act_fun):\n",
    "        super(Shallow_NOsharing_aux, self).__init__()\n",
    "        self.act_fun = act_fun\n",
    "        self.fc1_1 = nn.Linear(196, hidden)\n",
    "        self.fc1_2 = nn.Linear(196, hidden)\n",
    "        \n",
    "        # For classification with classes\n",
    "        self.fc_aux1 = nn.Linear(hidden, 10)\n",
    "        self.fc_aux2 = nn.Linear(hidden, 10)\n",
    "        \n",
    "        # After concatenation of the features from image 1 and image 2\n",
    "        self.fc2 = nn.Linear(hidden*2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.act_fun(self.fc1_1(x[:,0,:,:].view(-1,196)))\n",
    "        x2 = self.act_fun(self.fc1_2(x[:,1,:,:].view(-1,196)))\n",
    "        \n",
    "        aux1 = F.softmax(self.fc_aux1(x1),1)\n",
    "        aux2 = F.softmax(self.fc_aux2(x2),1)\n",
    "        \n",
    "        x = torch.cat([x1, x2],1)\n",
    "        x = self.fc2(x)       \n",
    "        return x, aux1, aux2\n",
    "    \n",
    "class Shallow_sharing_aux(nn.Module):\n",
    "    def __init__(self, hidden, act_fun):\n",
    "        super(Shallow_sharing_aux, self).__init__()\n",
    "        self.act_fun = act_fun\n",
    "        self.fc1 = nn.Linear(196, hidden)\n",
    "        \n",
    "        # For classification with classes\n",
    "        self.fc_aux1 = nn.Linear(hidden, 10)\n",
    "        self.fc_aux2 = nn.Linear(hidden, 10)\n",
    "        \n",
    "        # After concatenation of the features from image 1 and image 2\n",
    "        self.fc2 = nn.Linear(hidden*2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fc_image = []\n",
    "        for image in range(2):\n",
    "            x1 = self.act_fun(self.fc1(x[:,image,:,:].view(-1,196)))\n",
    "            fc_image.append(x1)\n",
    "        \n",
    "        aux1 = F.softmax(self.fc_aux1(fc_image[0]),1)\n",
    "        aux2 = F.softmax(self.fc_aux2(fc_image[1]),1)\n",
    "        \n",
    "        x = torch.cat([fc_image[0],fc_image[1]],1)\n",
    "        x = self.fc2(x)       \n",
    "        return x, aux1, aux2      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_NOsharing_NOaux(nn.Module):\n",
    "    def __init__(self, hidden, act_fun):\n",
    "        super(MLP_NOsharing_NOaux, self).__init__()\n",
    "        self.act_fun = act_fun\n",
    "        self.fc1_1 = nn.Linear(196, hidden)\n",
    "        self.fc1_2 = nn.Linear(196, hidden)\n",
    "        self.fc2_1 = nn.Linear(hidden,hidden)\n",
    "        self.fc2_2 = nn.Linear(hidden,hidden)\n",
    "        # After concatenation of the features from image 1 and image 2\n",
    "        self.fc3 = nn.Linear(hidden*2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1_1 = self.act_fun(self.fc1_1(x[:,0,:,:].view(-1,196)))\n",
    "        x1_2 = self.act_fun(self.fc1_2(x[:,1,:,:].view(-1,196)))\n",
    "        x2_1 = self.act_fun(self.fc2_1(x1_1))\n",
    "        x2_2 = self.act_fun(self.fc2_2(x1_2))\n",
    "        x = torch.cat([x2_1, x2_2],1)\n",
    "        x = self.fc3(x)       \n",
    "        return x\n",
    "\n",
    "class MLP_sharing_NOaux(nn.Module):\n",
    "    def __init__(self, hidden, act_fun):\n",
    "        super(MLP_sharing_NOaux, self).__init__()\n",
    "        self.act_fun = act_fun\n",
    "        self.fc1 = nn.Linear(196, hidden)\n",
    "        self.fc2 = nn.Linear(hidden,hidden)\n",
    "        # After concatenation of the features from image 1 and image 2\n",
    "        self.fc3 = nn.Linear(hidden*2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fc_image = []\n",
    "        for image in range(2):\n",
    "            x1 = self.act_fun(self.fc1(x[:,image,:,:].view(-1,196)))\n",
    "            x2 = self.act_fun(self.fc2(x1))\n",
    "            fc_image.append(x2)\n",
    "        x = torch.cat([fc_image[0],fc_image[1]],1)\n",
    "        x = self.fc3(x)       \n",
    "        return x\n",
    "    \n",
    "class MLP_NOsharing_aux(nn.Module):\n",
    "    def __init__(self, hidden, act_fun):\n",
    "        super(MLP_NOsharing_aux, self).__init__()\n",
    "        self.act_fun = act_fun\n",
    "        self.fc1_1 = nn.Linear(196, hidden)\n",
    "        self.fc1_2 = nn.Linear(196, hidden)\n",
    "        self.fc2_1 = nn.Linear(hidden,hidden)\n",
    "        self.fc2_2 = nn.Linear(hidden,hidden)\n",
    "        \n",
    "        # For classification with classes\n",
    "        self.fc_aux1 = nn.Linear(hidden, 10)\n",
    "        self.fc_aux2 = nn.Linear(hidden, 10)\n",
    "        \n",
    "        # After concatenation of the features from image 1 and image 2\n",
    "        self.fc3 = nn.Linear(hidden*2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1_1 = self.act_fun(self.fc1_1(x[:,0,:,:].view(-1,196)))\n",
    "        x1_2 = self.act_fun(self.fc1_2(x[:,1,:,:].view(-1,196)))\n",
    "        x2_1 = self.act_fun(self.fc2_1(x1_1))\n",
    "        x2_2 = self.act_fun(self.fc2_2(x1_2))\n",
    "        \n",
    "        aux1 = F.softmax(self.fc_aux1(x2_1),1)\n",
    "        aux2 = F.softmax(self.fc_aux2(x2_2),1)\n",
    "        \n",
    "        x = torch.cat([x2_1, x2_2],1)\n",
    "        x = self.fc3(x)       \n",
    "        return x, aux1, aux2\n",
    "    \n",
    "class MLP_sharing_aux(nn.Module):\n",
    "    def __init__(self, hidden, act_fun):\n",
    "        super(MLP_sharing_aux, self).__init__()\n",
    "        self.act_fun = act_fun\n",
    "        self.fc1 = nn.Linear(196, hidden)\n",
    "        self.fc2 = nn.Linear(hidden,hidden)\n",
    "        \n",
    "        # For classification with classes\n",
    "        self.fc_aux1 = nn.Linear(hidden, 10)\n",
    "        self.fc_aux2 = nn.Linear(hidden, 10)\n",
    "        \n",
    "        # After concatenation of the features from image 1 and image 2\n",
    "        self.fc3 = nn.Linear(hidden*2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fc_image = []\n",
    "        for image in range(2):\n",
    "            x1 = self.act_fun(self.fc1(x[:,image,:,:].view(-1,196)))\n",
    "            x2 = self.act_fun(self.fc2(x1))\n",
    "            fc_image.append(x2)\n",
    "            \n",
    "        aux1 = F.softmax(self.fc_aux1(fc_image[0]),1)\n",
    "        aux2 = F.softmax(self.fc_aux2(fc_image[1]),1)\n",
    "        \n",
    "        x = torch.cat([fc_image[0],fc_image[1]],1)\n",
    "        x = self.fc3(x)       \n",
    "        return x, aux1, aux2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deep_NOsharing_NOaux(nn.Module):\n",
    "    def __init__(self, hidden, act_fun):\n",
    "        super(Deep_NOsharing_NOaux, self).__init__()\n",
    "        self.act_fun = act_fun\n",
    "        self.conv1_1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv1_2 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2_1 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2_2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        \n",
    "        # After concatenation of the features from image 1 and image 2\n",
    "        self.fc1 = nn.Linear(512, hidden)\n",
    "        self.fc2 = nn.Linear(hidden,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1_1 = self.act_fun(F.max_pool2d(self.conv1_1(x[:,0,:,:].view(100,1,14,14)), kernel_size=2, stride=2))\n",
    "        x2_1 = self.act_fun(F.max_pool2d(self.conv2_1(x1_1), kernel_size=2, stride=2))\n",
    "        \n",
    "        x1_2 = self.act_fun(F.max_pool2d(self.conv1_2(x[:,1,:,:].view(100,1,14,14)), kernel_size=2, stride=2))\n",
    "        x2_2 = self.act_fun(F.max_pool2d(self.conv2_2(x1_2), kernel_size=2, stride=2))\n",
    "        \n",
    "        x = torch.cat([x2_1, x2_2],1)\n",
    "        x = self.act_fun(self.fc1(x.view(-1, 512)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Deep_sharing_NOaux(nn.Module):\n",
    "    def __init__(self, hidden, act_fun):\n",
    "        super(Deep_sharing_NOaux, self).__init__()\n",
    "        self.act_fun = act_fun\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        \n",
    "        # After concatenation of the features from image 1 and image 2\n",
    "        self.fc1 = nn.Linear(512, hidden)\n",
    "        self.fc2 = nn.Linear(hidden,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_images = []\n",
    "        for image in range(2):\n",
    "            first_conv = self.act_fun(F.max_pool2d(self.conv1(x[:,image,:,:].view(100,1,14,14)), kernel_size=2, stride=2))\n",
    "            conv_images.append(self.act_fun(F.max_pool2d(self.conv2(first_conv), kernel_size=2, stride=2)))\n",
    "        \n",
    "        x = torch.cat([conv_images[0], conv_images[1]],1)\n",
    "        x = self.act_fun(self.fc1(x.view(-1, 512)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class Deep_NOsharing_aux(nn.Module):\n",
    "    def __init__(self, hidden, act_fun):\n",
    "        super(Deep_NOsharing_aux, self).__init__()\n",
    "        self.act_fun = act_fun\n",
    "        self.conv1_1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv1_2 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2_1 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2_2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        \n",
    "        # For classification with classes\n",
    "        self.fc_aux1 = nn.Linear(256, 10)\n",
    "        self.fc_aux2 = nn.Linear(256, 10)\n",
    "        \n",
    "        # After concatenation of the features from image 1 and image 2\n",
    "        self.fc1 = nn.Linear(512, hidden)\n",
    "        self.fc2 = nn.Linear(hidden,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1_1 = self.act_fun(F.max_pool2d(self.conv1_1(x[:,0,:,:].view(100,1,14,14)), kernel_size=2, stride=2))\n",
    "        x2_1 = self.act_fun(F.max_pool2d(self.conv2_1(x1_1), kernel_size=2, stride=2))\n",
    "        \n",
    "        x1_2 = self.act_fun(F.max_pool2d(self.conv1_2(x[:,1,:,:].view(100,1,14,14)), kernel_size=2, stride=2))\n",
    "        x2_2 = self.act_fun(F.max_pool2d(self.conv2_2(x1_2), kernel_size=2, stride=2))\n",
    "\n",
    "        aux1 = F.softmax(self.fc_aux1(x2_1.view(-1,256)),1)\n",
    "        aux2 = F.softmax(self.fc_aux2(x2_2.view(-1,256)),1)\n",
    "        \n",
    "        x = torch.cat([x2_1, x2_2],1)\n",
    "        x = self.act_fun(self.fc1(x.view(-1, 512)))\n",
    "        x = self.fc2(x)\n",
    "        return x, aux1, aux2\n",
    "    \n",
    "class Deep_sharing_aux(nn.Module):\n",
    "    def __init__(self, hidden, act_fun):\n",
    "        super(Deep_sharing_aux, self).__init__()\n",
    "        self.act_fun = act_fun\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        \n",
    "        # For classification with classes\n",
    "        self.fc_aux1 = nn.Linear(256, 10)\n",
    "        self.fc_aux2 = nn.Linear(256, 10)\n",
    "        \n",
    "        # After concatenation of the features from image 1 and image 2\n",
    "        self.fc1 = nn.Linear(512, hidden)\n",
    "        self.fc2 = nn.Linear(hidden,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_images = []\n",
    "        for image in range(2):\n",
    "            first_conv = self.act_fun(F.max_pool2d(self.conv1(x[:,image,:,:].view(100,1,14,14)), kernel_size=2, stride=2))\n",
    "            conv_images.append(self.act_fun(F.max_pool2d(self.conv2(first_conv), kernel_size=2, stride=2)))\n",
    "            \n",
    "        aux1 = F.softmax(self.fc_aux1(conv_images[0].view(-1,256)),1)\n",
    "        aux2 = F.softmax(self.fc_aux2(conv_images[1].view(-1,256)),1)\n",
    "        \n",
    "        x = torch.cat([conv_images[0], conv_images[1]],1)\n",
    "        x = self.act_fun(self.fc1(x.view(-1, 512)))\n",
    "        x = self.fc2(x)\n",
    "        return x, aux1, aux2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deep_NOsharing_NOaux2(nn.Module):\n",
    "    def __init__(self, hidden, act_fun):\n",
    "        super(Deep_NOsharing_NOaux2, self).__init__()\n",
    "        self.act_fun = act_fun\n",
    "        self.conv1_1 = nn.Conv2d(1, 16, kernel_size=5)\n",
    "        self.conv1_2 = nn.Conv2d(1, 16, kernel_size=5)\n",
    "        self.conv2_1 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.conv2_2 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.conv3_1 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv3_2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(64, 128, kernel_size=2)\n",
    "        self.conv4_2 = nn.Conv2d(64, 128, kernel_size=2)\n",
    "        \n",
    "        # After concatenation of the features from image 1 and image 2\n",
    "        self.fc1 = nn.Linear(1024, hidden)\n",
    "        self.fc2 = nn.Linear(hidden,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1_1 = self.act_fun(self.conv1_1(x[:,0,:,:].view(100,1,14,14)))\n",
    "        x2_1 = self.act_fun(self.conv2_1(x1_1))\n",
    "        x3_1 = self.act_fun(self.conv3_2(x2_1))\n",
    "        x4_1 = self.act_fun(F.max_pool2d(self.conv4_1(x3_1), kernel_size=2, stride=2))\n",
    "        \n",
    "        x1_2 = self.act_fun(self.conv1_2(x[:,1,:,:].view(100,1,14,14)))\n",
    "        x2_2 = self.act_fun(self.conv2_2(x1_2))\n",
    "        x3_2 = self.act_fun(self.conv3_2(x2_2))\n",
    "        x4_2 = self.act_fun(F.max_pool2d(self.conv4_2(x3_2), kernel_size=2, stride=2))\n",
    "\n",
    "        x = torch.cat([x4_1, x4_2],1)\n",
    "        x = self.act_fun(self.fc1(x.view(-1, 1024)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Deep_sharing_NOaux2(nn.Module):\n",
    "    def __init__(self, hidden, act_fun):\n",
    "        super(Deep_sharing_NOaux2, self).__init__()\n",
    "        self.act_fun = act_fun\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=2)\n",
    "        \n",
    "        # After concatenation of the features from image 1 and image 2\n",
    "        self.fc1 = nn.Linear(1024, hidden)\n",
    "        self.fc2 = nn.Linear(hidden,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_images = []\n",
    "        for image in range(2):\n",
    "            x1 = self.act_fun(self.conv1(x[:,image,:,:].view(100,1,14,14)))\n",
    "            x2 = self.act_fun(self.conv2(x1))\n",
    "            x3 = self.act_fun(self.conv3(x2))\n",
    "            x4 = self.act_fun(F.max_pool2d(self.conv4(x3), kernel_size=2, stride=2))\n",
    "            conv_images.append(x4)\n",
    "        \n",
    "        x = torch.cat([conv_images[0], conv_images[1]],1)\n",
    "        x = self.act_fun(self.fc1(x.view(-1, 1024)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class Deep_NOsharing_aux2(nn.Module):\n",
    "    def __init__(self, hidden, act_fun):\n",
    "        super(Deep_NOsharing_aux2, self).__init__()\n",
    "        self.act_fun = act_fun\n",
    "        self.conv1_1 = nn.Conv2d(1, 16, kernel_size=5)\n",
    "        self.conv1_2 = nn.Conv2d(1, 16, kernel_size=5)\n",
    "        self.conv2_1 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.conv2_2 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.conv3_1 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv3_2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(64, 128, kernel_size=2)\n",
    "        self.conv4_2 = nn.Conv2d(64, 128, kernel_size=2)\n",
    "        \n",
    "        # For classification with classes\n",
    "        self.fc_aux1 = nn.Linear(512, 10)\n",
    "        self.fc_aux2 = nn.Linear(512, 10)\n",
    "        \n",
    "        # After concatenation of the features from image 1 and image 2\n",
    "        self.fc1 = nn.Linear(1024, hidden)\n",
    "        self.fc2 = nn.Linear(hidden,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1_1 = self.act_fun(self.conv1_1(x[:,0,:,:].view(100,1,14,14)))\n",
    "        x2_1 = self.act_fun(self.conv2_1(x1_1))\n",
    "        x3_1 = self.act_fun(self.conv3_2(x2_1))\n",
    "        x4_1 = self.act_fun(F.max_pool2d(self.conv4_1(x3_1), kernel_size=2, stride=2))\n",
    "        \n",
    "        x1_2 = self.act_fun(self.conv1_2(x[:,1,:,:].view(100,1,14,14)))\n",
    "        x2_2 = self.act_fun(self.conv2_2(x1_2))\n",
    "        x3_2 = self.act_fun(self.conv3_2(x2_2))\n",
    "        x4_2 = self.act_fun(F.max_pool2d(self.conv4_2(x3_2), kernel_size=2, stride=2))\n",
    "\n",
    "        aux1 = F.softmax(self.fc_aux1(x4_1.view(-1,512)),1)\n",
    "        aux2 = F.softmax(self.fc_aux2(x4_2.view(-1,512)),1)\n",
    "        \n",
    "        x = torch.cat([x4_1, x4_2],1)\n",
    "        x = self.act_fun(self.fc1(x.view(-1, 1024)))\n",
    "        x = self.fc2(x)\n",
    "        return x, aux1, aux2\n",
    "    \n",
    "class Deep_sharing_aux2(nn.Module):\n",
    "    def __init__(self, hidden, act_fun):\n",
    "        super(Deep_sharing_aux2, self).__init__()\n",
    "        self.act_fun = act_fun\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=2)\n",
    "        \n",
    "        # For classification with classes\n",
    "        self.fc_aux1 = nn.Linear(512, 10)\n",
    "        self.fc_aux2 = nn.Linear(512, 10)\n",
    "        \n",
    "        # After concatenation of the features from image 1 and image 2\n",
    "        self.fc1 = nn.Linear(1024, hidden)\n",
    "        self.fc2 = nn.Linear(hidden,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_images = []\n",
    "        for image in range(2):\n",
    "            x1 = self.act_fun(self.conv1(x[:,image,:,:].view(100,1,14,14)))\n",
    "            x2 = self.act_fun(self.conv2(x1))\n",
    "            x3 = self.act_fun(self.conv3(x2))\n",
    "            x4 = self.act_fun(F.max_pool2d(self.conv4(x3), kernel_size=2, stride=2))\n",
    "            conv_images.append(x4)\n",
    "            \n",
    "        aux1 = F.softmax(self.fc_aux1(conv_images[0].view(-1,512)),1)\n",
    "        aux2 = F.softmax(self.fc_aux2(conv_images[1].view(-1,512)),1)\n",
    "        \n",
    "        x = torch.cat([conv_images[0], conv_images[1]],1)\n",
    "        x = self.act_fun(self.fc1(x.view(-1, 1024)))\n",
    "        x = self.fc2(x)\n",
    "        return x, aux1, aux2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(input_, target, hidden_units, eta, lambda_, model_type = 'Shallow', sharing = False, \n",
    "                aux = False,  nb_epochs = 25, mini_batch_size = 100, criterion = nn.CrossEntropyLoss()):\n",
    "    if(model_type == 'Shallow'):\n",
    "        if(sharing):\n",
    "            if(aux): model = Shallow_sharing_aux(hidden = hidden_units, act_fun = F.relu)\n",
    "            else: model = Shallow_sharing_NOaux(hidden = hidden_units, act_fun = F.relu)\n",
    "        else:\n",
    "            if(aux): model = Shallow_NOsharing_aux(hidden = hidden_units, act_fun = F.relu)\n",
    "            else: model = Shallow_NOsharing_NOaux(hidden = hidden_units, act_fun = F.relu)\n",
    "    elif(model_type == 'MLP'):\n",
    "        if(sharing):\n",
    "            if(aux): model = MLP_sharing_aux(hidden = hidden_units, act_fun = F.relu)\n",
    "            else: model = MLP_sharing_NOaux(hidden = hidden_units, act_fun = F.relu)\n",
    "        else:\n",
    "            if(aux): model = MLP_NOsharing_aux(hidden = hidden_units, act_fun = F.relu)\n",
    "            else: model = MLP_NOsharing_NOaux(hidden = hidden_units, act_fun = F.relu)\n",
    "    elif(model_type == 'Deep1'):\n",
    "        if(sharing):\n",
    "            if(aux): model = Deep_sharing_aux(hidden = hidden_units, act_fun = F.relu)\n",
    "            else: model = Deep_sharing_NOaux(hidden = hidden_units, act_fun = F.relu)\n",
    "        else:\n",
    "            if(aux): model = Deep_NOsharing_aux(hidden = hidden_units, act_fun = F.relu)\n",
    "            else: model = Deep_NOsharing_NOaux(hidden = hidden_units, act_fun = F.relu)\n",
    "    elif(model_type == 'Deep2'):\n",
    "        if(sharing):\n",
    "            if(aux): model = Deep_sharing_aux2(hidden = hidden_units, act_fun = F.relu)\n",
    "            else: model = Deep_sharing_NOaux2(hidden = hidden_units, act_fun = F.relu)\n",
    "        else:\n",
    "            if(aux): model = Deep_NOsharing_aux2(hidden = hidden_units, act_fun = F.relu)\n",
    "            else: model = Deep_NOsharing_NOaux2(hidden = hidden_units, act_fun = F.relu)\n",
    "                \n",
    "    if(aux): \n",
    "        train_model_aux(model, input_[:700], target[:700], nb_epochs, mini_batch_size, criterion, eta, lambda_)\n",
    "        accuracy = 1 - compute_nb_errors_aux(model, input_[700:], target[700:], mini_batch_size)/len(target)\n",
    "    else: \n",
    "        train_model_NOaux(model, input_[:700], target[:700], nb_epochs, mini_batch_size, criterion, eta)\n",
    "        accuracy = 1 - compute_nb_errors_NOaux(model, input_[700:], target[700:], mini_batch_size)/len(target)\n",
    "        \n",
    "    #print(model_type, sharing, 'Sharing and', aux, 'Aux =', accuracy)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_(lambdas, etas, hidden_units, input_, target):\n",
    "    type_models = ['Shallow', 'MLP', 'Deep1', 'Deep2']\n",
    "    sharing_flags = [True, False]\n",
    "    aux_flags = [True, False]\n",
    "    \n",
    "    for type_model in type_models:\n",
    "        for sharing_flag in sharing_flags:\n",
    "            for aux_flag in aux_flags:\n",
    "                performances = torch.zeros(len(lambdas),len(hidden_units),len(etas))\n",
    "                print('')\n",
    "                for l,lambda_ in enumerate(lambdas):\n",
    "                    for h,hidden in enumerate(hidden_units):\n",
    "                        for e,eta in enumerate(etas):\n",
    "                            acc = predictions(input_,target, hidden.item(), eta.item(), lambda_.item(),\n",
    "                                              model_type = type_model, sharing = sharing_flag, aux = aux_flag)\n",
    "                            performances[l,h,e] = acc\n",
    "                best_performance = torch.max(performances)\n",
    "                best_idx = (performances == best_performance).nonzero();\n",
    "                \n",
    "                best_eta = etas[best_idx[0,2]]\n",
    "                best_hidden = hidden_units[best_idx[0,1]]\n",
    "                best_lambda = lambdas[best_idx[0,0]]\n",
    "                \n",
    "                print('Model: ', type_model, ', Sharing = ', sharing_flag, ', Aux = ', aux_flag )\n",
    "                print('Best performance = ', best_performance.item())\n",
    "                print('Best combination of Hyperparameters:')\n",
    "                print('Eta = ', best_eta.item(), 'Number of hidden units = ', best_hidden.item(), \n",
    "                      'Lambda = ', best_lambda.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.5000])\n",
      "\n",
      "Model:  Shallow , Sharing =  True , Aux =  True\n",
      "Best performance =  0.9509999752044678\n",
      "Best combination of Hyperparameters:\n",
      "Eta =  0.0010000000474974513 Number of hidden units =  220 Lambda =  0.0\n",
      "\n",
      "Model:  Shallow , Sharing =  True , Aux =  False\n",
      "Best performance =  0.9430000185966492\n",
      "Best combination of Hyperparameters:\n",
      "Eta =  0.0010000000474974513 Number of hidden units =  290 Lambda =  0.0\n",
      "\n",
      "Model:  Shallow , Sharing =  False , Aux =  True\n",
      "Best performance =  0.9390000104904175\n",
      "Best combination of Hyperparameters:\n",
      "Eta =  0.0010000000474974513 Number of hidden units =  290 Lambda =  0.0\n",
      "\n",
      "Model:  Shallow , Sharing =  False , Aux =  False\n",
      "Best performance =  0.9449999928474426\n",
      "Best combination of Hyperparameters:\n",
      "Eta =  0.0010000000474974513 Number of hidden units =  290 Lambda =  0.5\n",
      "\n",
      "Model:  MLP , Sharing =  True , Aux =  True\n",
      "Best performance =  0.9570000171661377\n",
      "Best combination of Hyperparameters:\n",
      "Eta =  0.0010000000474974513 Number of hidden units =  290 Lambda =  0.5\n",
      "\n",
      "Model:  MLP , Sharing =  True , Aux =  False\n",
      "Best performance =  0.9520000219345093\n",
      "Best combination of Hyperparameters:\n",
      "Eta =  0.0010000000474974513 Number of hidden units =  220 Lambda =  0.5\n",
      "\n",
      "Model:  MLP , Sharing =  False , Aux =  True\n",
      "Best performance =  0.9459999799728394\n",
      "Best combination of Hyperparameters:\n",
      "Eta =  0.0010000000474974513 Number of hidden units =  290 Lambda =  0.5\n",
      "\n",
      "Model:  MLP , Sharing =  False , Aux =  False\n",
      "Best performance =  0.9509999752044678\n",
      "Best combination of Hyperparameters:\n",
      "Eta =  0.0010000000474974513 Number of hidden units =  290 Lambda =  0.0\n",
      "\n",
      "Model:  Deep1 , Sharing =  True , Aux =  True\n",
      "Best performance =  0.9520000219345093\n",
      "Best combination of Hyperparameters:\n",
      "Eta =  0.0010000000474974513 Number of hidden units =  80 Lambda =  0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lambdas = torch.arange(0,1,0.5)\n",
    "etas = torch.logspace(-3,-3,1)\n",
    "hidden_units = torch.arange(10,310,70)\n",
    "\n",
    "grid_search_(lambdas, etas, hidden_units, train_input, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_size = 100\n",
    "nb_epochs = 25\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "eta = 0.001\n",
    "hidden_units = 300\n",
    "\n",
    "# Shallow\n",
    "model_shallow_NOsharing_NOaux = Shallow_NOsharing_NOaux(hidden = hidden_units, act_fun = F.relu)\n",
    "model_shallow_sharing_NOaux = Shallow_sharing_NOaux(hidden = hidden_units, act_fun = F.relu)\n",
    "model_shallow_NOsharing_aux = Shallow_NOsharing_aux(hidden = hidden_units, act_fun = F.relu)\n",
    "model_shallow_sharing_aux = Shallow_sharing_aux(hidden = hidden_units, act_fun = F.relu)\n",
    "\n",
    "#MLP\n",
    "model_MLP_NOsharing_NOaux = MLP_NOsharing_NOaux(hidden = hidden_units, act_fun = F.relu)\n",
    "model_MLP_sharing_NOaux = MLP_sharing_NOaux(hidden = hidden_units, act_fun = F.relu)\n",
    "model_MLP_NOsharing_aux = MLP_NOsharing_aux(hidden = hidden_units, act_fun = F.relu)\n",
    "model_MLP_sharing_aux = MLP_sharing_aux(hidden = hidden_units, act_fun = F.relu)\n",
    "\n",
    "#Deep1\n",
    "model_deep_NOsharing_NOaux = Deep_NOsharing_NOaux(hidden = hidden_units, act_fun = F.relu)\n",
    "model_deep_sharing_NOaux = Deep_sharing_NOaux(hidden = hidden_units, act_fun = F.relu)\n",
    "model_deep_NOsharing_aux = Deep_NOsharing_aux(hidden = hidden_units, act_fun = F.relu)\n",
    "model_deep_sharing_aux = Deep_sharing_aux(hidden = hidden_units, act_fun = F.relu)\n",
    "\n",
    "#Deep2\n",
    "model_deep_NOsharing_NOaux2 = Deep_NOsharing_NOaux2(hidden = hidden_units, act_fun = F.relu)\n",
    "model_deep_sharing_NOaux2 = Deep_sharing_NOaux2(hidden = hidden_units, act_fun = F.relu)\n",
    "model_deep_NOsharing_aux2 = Deep_NOsharing_aux2(hidden = hidden_units, act_fun = F.relu)\n",
    "model_deep_sharing_aux2 = Deep_sharing_aux2(hidden = hidden_units, act_fun = F.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shallow\n",
    "train_model_NOaux(model_shallow_NOsharing_NOaux, train_input, train_target,nb_epochs, mini_batch_size, criterion, eta)\n",
    "train_model_NOaux(model_shallow_sharing_NOaux, train_input, train_target,nb_epochs, mini_batch_size, criterion, eta)\n",
    "train_model_aux(model_shallow_NOsharing_aux, train_input, train_target,nb_epochs, mini_batch_size, criterion, eta, 0.5)\n",
    "train_model_aux(model_shallow_sharing_aux, train_input, train_target,nb_epochs, mini_batch_size, criterion, eta, 0.5)\n",
    "\n",
    "#MLP\n",
    "train_model_NOaux(model_MLP_NOsharing_NOaux, train_input, train_target,nb_epochs, mini_batch_size, criterion, eta)\n",
    "train_model_NOaux(model_MLP_sharing_NOaux, train_input, train_target,nb_epochs, mini_batch_size, criterion, eta)\n",
    "train_model_aux(model_MLP_NOsharing_aux, train_input, train_target,nb_epochs, mini_batch_size, criterion, eta, 0.5)\n",
    "train_model_aux(model_MLP_sharing_aux, train_input, train_target,nb_epochs, mini_batch_size, criterion, eta, 0.5)\n",
    "\n",
    "#Deep1\n",
    "train_model_NOaux(model_deep_sharing_NOaux, train_input, train_target,nb_epochs, mini_batch_size, criterion, eta)\n",
    "train_model_NOaux(model_deep_NOsharing_NOaux, train_input, train_target,nb_epochs, mini_batch_size, criterion, eta)\n",
    "train_model_aux(model_deep_NOsharing_aux, train_input, train_target,nb_epochs, mini_batch_size, criterion, eta, 0.5)\n",
    "train_model_aux(model_deep_sharing_aux, train_input, train_target,nb_epochs, mini_batch_size, criterion, eta, 0.5)\n",
    "\n",
    "#Deep2\n",
    "train_model_NOaux(model_deep_sharing_NOaux2, train_input, train_target,nb_epochs, mini_batch_size, criterion, eta)\n",
    "train_model_NOaux(model_deep_NOsharing_NOaux2, train_input, train_target,nb_epochs, mini_batch_size, criterion, eta)\n",
    "train_model_aux(model_deep_NOsharing_aux2, train_input, train_target,nb_epochs, mini_batch_size, criterion, eta, 0.5)\n",
    "train_model_aux(model_deep_sharing_aux2, train_input, train_target,nb_epochs, mini_batch_size, criterion, eta, 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train performance shallow NOsharing NOaux =  1.0\n",
      "Train performance shallow sharing Noaux =  1.0\n",
      "Train performance shallow NOsharing aux =  1.0\n",
      "Train performance shallow sharing aux =  0.999\n",
      "Train performance MLP NOsharing NOaux =  1.0\n",
      "Train performance MLP sharing Noaux =  1.0\n",
      "Train performance MLP NOsharing aux =  1.0\n",
      "Train performance MLP sharing aux =  1.0\n",
      "Train performance Deep NOsharing NOaux =  0.979\n",
      "Train performance Deep sharing Noaux =  0.998\n",
      "Train performance Deep NOsharing aux =  0.995\n",
      "Train performance Deep sharing aux =  0.999\n",
      "Train performance Deep NOsharing NOaux 2 =  0.999\n",
      "Train performance Deep sharing Noaux 2 =  0.999\n",
      "Train performance Deep NOsharing aux 2 =  0.999\n",
      "Train performance Deep sharing aux 2 =  0.999\n",
      "\n",
      "Test performance shallow NOsharing NOaux =  0.7969999999999999\n",
      "Test performance shallow sharing Noaux =  0.802\n",
      "Test performance shallow NOsharing aux =  0.7989999999999999\n",
      "Test performance shallow sharing aux =  0.808\n",
      "Test performance MLP NOsharing NOaux =  0.83\n",
      "Test performance MLP sharing Noaux =  0.821\n",
      "Test performance MLP NOsharing aux =  0.8200000000000001\n",
      "Test performance MLP sharing aux =  0.8200000000000001\n",
      "Test performance Deep NOsharing NOaux =  0.817\n",
      "Test performance Deep sharing Noaux =  0.823\n",
      "Test performance Deep NOsharing aux =  0.84\n",
      "Test performance Deep sharing aux =  0.841\n",
      "Test performance Deep NOsharing NOaux 2 =  0.823\n",
      "Test performance Deep sharing Noaux 2 =  0.834\n",
      "Test performance Deep NOsharing aux 2 =  0.829\n",
      "Test performance Deep sharing aux 2 =  0.863\n"
     ]
    }
   ],
   "source": [
    "#Shallow\n",
    "train_acc_shallow_NOsharing_NOaux = 1 - compute_nb_errors_NOaux(model_shallow_NOsharing_NOaux, train_input, train_target, mini_batch_size)\n",
    "train_acc_shallow_sharing_NOaux  = 1 - compute_nb_errors_NOaux(model_shallow_sharing_NOaux, train_input, train_target, mini_batch_size)\n",
    "train_acc_shallow_NOsharing_aux  = 1 - compute_nb_errors_aux(model_shallow_NOsharing_aux, train_input, train_target, mini_batch_size)\n",
    "train_acc_shallow_sharing_aux  = 1 - compute_nb_errors_aux(model_shallow_sharing_aux, train_input, train_target, mini_batch_size)\n",
    "\n",
    "#MLP\n",
    "train_acc_MLP_NOsharing_NOaux = 1 - compute_nb_errors_NOaux(model_MLP_NOsharing_NOaux, train_input, train_target, mini_batch_size)\n",
    "train_acc_MLP_sharing_NOaux = 1 - compute_nb_errors_NOaux(model_MLP_sharing_NOaux, train_input, train_target, mini_batch_size)\n",
    "train_acc_MLP_NOsharing_aux = 1 - compute_nb_errors_aux(model_MLP_NOsharing_aux, train_input, train_target, mini_batch_size)\n",
    "train_acc_MLP_sharing_aux = 1 - compute_nb_errors_aux(model_MLP_sharing_aux, train_input, train_target, mini_batch_size)\n",
    "\n",
    "#Deep1\n",
    "train_acc_deep_NOsharing_NOaux = 1 - compute_nb_errors_NOaux(model_deep_NOsharing_NOaux, train_input, train_target, mini_batch_size)\n",
    "train_acc_deep_sharing_NOaux = 1 - compute_nb_errors_NOaux(model_deep_sharing_NOaux, train_input, train_target, mini_batch_size)\n",
    "train_acc_deep_NOsharing_aux = 1 - compute_nb_errors_aux(model_deep_NOsharing_aux, train_input, train_target, mini_batch_size)\n",
    "train_acc_deep_sharing_aux = 1 - compute_nb_errors_aux(model_deep_sharing_aux, train_input, train_target, mini_batch_size)\n",
    "\n",
    "#Deep2\n",
    "train_acc_deep_NOsharing_NOaux2 = 1 - compute_nb_errors_NOaux(model_deep_NOsharing_NOaux2, train_input, train_target, mini_batch_size)\n",
    "train_acc_deep_sharing_NOaux2 = 1 - compute_nb_errors_NOaux(model_deep_sharing_NOaux2, train_input, train_target, mini_batch_size)\n",
    "train_acc_deep_NOsharing_aux2 = 1 - compute_nb_errors_aux(model_deep_NOsharing_aux2, train_input, train_target, mini_batch_size)\n",
    "train_acc_deep_sharing_aux2 = 1 - compute_nb_errors_aux(model_deep_sharing_aux2, train_input, train_target, mini_batch_size)\n",
    "\n",
    "print('Train performance shallow NOsharing NOaux = ', train_acc_shallow_NOsharing_NOaux)\n",
    "print('Train performance shallow sharing Noaux = ', train_acc_shallow_sharing_NOaux)\n",
    "print('Train performance shallow NOsharing aux = ', train_acc_shallow_NOsharing_aux)\n",
    "print('Train performance shallow sharing aux = ', train_acc_shallow_sharing_aux)\n",
    "\n",
    "print('Train performance MLP NOsharing NOaux = ', train_acc_MLP_NOsharing_NOaux)\n",
    "print('Train performance MLP sharing Noaux = ', train_acc_MLP_sharing_NOaux)\n",
    "print('Train performance MLP NOsharing aux = ', train_acc_MLP_NOsharing_aux)\n",
    "print('Train performance MLP sharing aux = ', train_acc_MLP_sharing_aux)\n",
    "\n",
    "print('Train performance Deep NOsharing NOaux = ', train_acc_deep_NOsharing_NOaux)\n",
    "print('Train performance Deep sharing Noaux = ', train_acc_deep_sharing_NOaux)\n",
    "print('Train performance Deep NOsharing aux = ', train_acc_deep_NOsharing_aux)\n",
    "print('Train performance Deep sharing aux = ', train_acc_deep_sharing_aux)\n",
    "\n",
    "print('Train performance Deep NOsharing NOaux 2 = ', train_acc_deep_NOsharing_NOaux2)\n",
    "print('Train performance Deep sharing Noaux 2 = ', train_acc_deep_sharing_NOaux2)\n",
    "print('Train performance Deep NOsharing aux 2 = ', train_acc_deep_NOsharing_aux2)\n",
    "print('Train performance Deep sharing aux 2 = ', train_acc_deep_sharing_aux2)\n",
    "\n",
    "#Shallow\n",
    "test_acc_shallow_NOsharing_NOaux = 1 - compute_nb_errors_NOaux(model_shallow_NOsharing_NOaux, test_input, test_target, mini_batch_size)\n",
    "test_acc_shallow_sharing_NOaux = 1 - compute_nb_errors_NOaux(model_shallow_sharing_NOaux, test_input, test_target, mini_batch_size)\n",
    "test_acc_shallow_NOsharing_aux = 1 - compute_nb_errors_aux(model_shallow_NOsharing_aux, test_input, test_target, mini_batch_size)\n",
    "test_acc_shallow_sharing_aux = 1 - compute_nb_errors_aux(model_shallow_sharing_aux, test_input, test_target, mini_batch_size)\n",
    "\n",
    "#MLP\n",
    "test_acc_MLP_NOsharing_NOaux = 1 - compute_nb_errors_NOaux(model_MLP_NOsharing_NOaux, test_input, test_target, mini_batch_size)\n",
    "test_acc_MLP_sharing_NOaux = 1 - compute_nb_errors_NOaux(model_MLP_sharing_NOaux, test_input, test_target, mini_batch_size)\n",
    "test_acc_MLP_NOsharing_aux = 1 - compute_nb_errors_aux(model_MLP_NOsharing_aux, test_input, test_target, mini_batch_size)\n",
    "test_acc_MLP_sharing_aux = 1 - compute_nb_errors_aux(model_MLP_sharing_aux, test_input, test_target, mini_batch_size)\n",
    "\n",
    "#Deep1\n",
    "test_acc_deep_NOsharing_NOaux = 1 - compute_nb_errors_NOaux(model_deep_NOsharing_NOaux, test_input, test_target, mini_batch_size)\n",
    "test_acc_deep_sharing_NOaux = 1 - compute_nb_errors_NOaux(model_deep_sharing_NOaux, test_input, test_target, mini_batch_size)\n",
    "test_acc_deep_NOsharing_aux = 1 - compute_nb_errors_aux(model_deep_NOsharing_aux, test_input, test_target, mini_batch_size)\n",
    "test_acc_deep_sharing_aux = 1 - compute_nb_errors_aux(model_deep_sharing_aux, test_input, test_target, mini_batch_size)\n",
    "\n",
    "#Deep2\n",
    "test_acc_deep_NOsharing_NOaux2 = 1 - compute_nb_errors_NOaux(model_deep_NOsharing_NOaux2, test_input, test_target, mini_batch_size)\n",
    "test_acc_deep_sharing_NOaux2 = 1 - compute_nb_errors_NOaux(model_deep_sharing_NOaux2, test_input, test_target, mini_batch_size)\n",
    "test_acc_deep_NOsharing_aux2 = 1 - compute_nb_errors_aux(model_deep_NOsharing_aux2, test_input, test_target, mini_batch_size)\n",
    "test_acc_deep_sharing_aux2 = 1 - compute_nb_errors_aux(model_deep_sharing_aux2, test_input, test_target, mini_batch_size)\n",
    "\n",
    "print('')\n",
    "print('Test performance shallow NOsharing NOaux = ', test_acc_shallow_NOsharing_NOaux)\n",
    "print('Test performance shallow sharing Noaux = ', test_acc_shallow_sharing_NOaux)\n",
    "print('Test performance shallow NOsharing aux = ', test_acc_shallow_NOsharing_aux)\n",
    "print('Test performance shallow sharing aux = ', test_acc_shallow_sharing_aux)\n",
    "\n",
    "print('Test performance MLP NOsharing NOaux = ', test_acc_MLP_NOsharing_NOaux)\n",
    "print('Test performance MLP sharing Noaux = ', test_acc_MLP_sharing_NOaux)\n",
    "print('Test performance MLP NOsharing aux = ', test_acc_MLP_NOsharing_aux)\n",
    "print('Test performance MLP sharing aux = ', test_acc_MLP_sharing_aux)\n",
    "\n",
    "print('Test performance Deep NOsharing NOaux = ', test_acc_deep_NOsharing_NOaux)\n",
    "print('Test performance Deep sharing Noaux = ', test_acc_deep_sharing_NOaux)\n",
    "print('Test performance Deep NOsharing aux = ', test_acc_deep_NOsharing_aux)\n",
    "print('Test performance Deep sharing aux = ', test_acc_deep_sharing_aux)\n",
    "\n",
    "print('Test performance Deep NOsharing NOaux 2 = ', test_acc_deep_NOsharing_NOaux2)\n",
    "print('Test performance Deep sharing Noaux 2 = ', test_acc_deep_sharing_NOaux2)\n",
    "print('Test performance Deep NOsharing aux 2 = ', test_acc_deep_NOsharing_aux2)\n",
    "print('Test performance Deep sharing aux 2 = ', test_acc_deep_sharing_aux2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
